# -*- coding: utf-8 -*-
"""Copy of Copy of DL_HW1 TransformersG.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZsbhvzNgpCGTBEewcv1A_UV3fgBONVWh
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install transformers --quiet
!pip install datasets --quiet
!pip install evaluate --quiet

#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
from huggingface_hub import notebook_login
notebook_login()

from datasets import load_dataset
#dataset = load_dataset('csv', data_files={'train': 'drive/MyDrive/DL_HW1/mix_train.csv', 'valid': 'drive/MyDrive/DL_HW1/mix_valid.csv'})
dataset = load_dataset('csv', data_files={'train': '/content/drive/MyDrive/DL/mix_train.csv', 'valid': '/content/drive/MyDrive/DL/mix_valid.csv'})

import re
import numpy as np
import pandas as pd
from wordcloud import WordCloud, STOPWORDS

import plotly.express as px
import plotly.graph_objects as go
import plotly.figure_factory as ff
from plotly.subplots import make_subplots

from sklearn.model_selection import train_test_split

from datasets import load_dataset
from datasets import Dataset

from datasets import load_metric

import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig, DataCollatorWithPadding, TrainingArguments, Trainer

import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoConfig, DataCollatorWithPadding
  
checkpoint = "bert-base-cased"
tokenizer = AutoTokenizer.from_pretrained(checkpoint)

dataset["train"][4]

def preprocess_function(examples):
    return tokenizer(examples["bio"], truncation=True)
    # return tokenizer(examples["text"], truncation=True)

tokenized_dataset = dataset.map(preprocess_function, batched=True)

data_collator = DataCollatorWithPadding(tokenizer=tokenizer)

import evaluate
accuracy = evaluate.load("accuracy")

import numpy as np

def compute_metrics(eval_pred):
    predictions, labels = eval_pred
    predictions = np.argmax(predictions, axis=1)
    return accuracy.compute(predictions=predictions, references=labels)

id2label = {0: "FAKE", 1: "REAL"}
label2id = {"REAL": 0, "FAKE": 1}

model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2, id2label=id2label, label2id=label2id)

training_args = TrainingArguments(
    output_dir="bert_base_cased_fake_real_3",
    learning_rate=2e-5,
    per_device_train_batch_size=16,
    per_device_eval_batch_size=16,
    num_train_epochs=2,
    weight_decay=0.01,
    evaluation_strategy="epoch",
    save_strategy="epoch",
    load_best_model_at_end=True,
    push_to_hub=True,
)

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=tokenized_dataset["train"],
    eval_dataset=tokenized_dataset["valid"],
    tokenizer=tokenizer,
    data_collator=data_collator,
    compute_metrics=compute_metrics
)

trainer.train()

from transformers import AutoTokenizer, AutoModelForSequenceClassification

tokenizer = AutoTokenizer.from_pretrained("VA777/bert_base_cased_fake_real_3")
model = AutoModelForSequenceClassification.from_pretrained("VA777/bert_base_cased_fake_real_3")

from transformers import pipeline
classifier = pipeline(model="VA777/bert_base_cased_fake_real_3",tokenizer="VA777/bert_base_cased_fake_real_3", max_length=512, truncation=True)

classifier("<start_bio>   = Oleksander Konstantinovich Preobrazhensky =   Oleksandr Konstantinovich Preobrazhensky ( Russian : Николай Андре́й Андрович Новной, ; 20 October 1902 – 15 April 1987 ) was a Soviet geologist.            == Biography ==    Preobrazhensky was born on 20 October 1902 in Besansky, Ukraine, into a family of prominent men in the banking industry. He attended Besansky Gymnasium ( Russian : Пергелогич Кунса ), where he was a student of Vladimir Sedevik. His father Eduard Preobrazhensky was the leading banker and an influential member of the Soviet elite. Another son, Oleg Preobrazhensky was also a leading figure in the banking industry, and, like his father, was a patriarch in the Besansky community. At Besansky, Oleksandr spent his early years getting a normal education. His second year he went to Besansky Polytechnic Institute to study philosophy. When Preobrazhensky graduated from Besansky, he chose to continue his education at an extremely elite departmental institution, the Department of Geology of the Department of Metallurgy. At that time, geology was a sub-specialty, which made it almost impossible to find an excellent candidate for that particular field. Moreover, there was a significant degree of skepticism among Western scientific societies. Even the relatively conservative American Geologist Robert Louis Stevenson had not accepted the accepted field of geology. Nonetheless, his experience and professional interests in the subject were quite well known within the U.S.A. As a result, Preobrazhensky was recommended to the director of the Metallurgy Department, Alexander N. Baker. In 1944, the Government of the Soviet Union gave Preobrazhensky the rank of Major General and promoted him to Major General. In 1945, he became a Vice-President of the USSR Academy of Sciences.    Preobrazhensky left Besansky for Leningrad in 1949, just before the Soviet government was launched into full democracy. He arrived in Leningrad at the height of the summer Soviet working week, in the midst of the Great Patriotic War, and on a busy time-frame. Preobrazhensky had spent several months as a Soviet Deputy Foreign Minister at the United Nations. During this period, he worked closely with the first Soviet Geologist of Geological Sciences, Alexander Landov. Through this foundation of knowledge, which lasted for a number of years, he produced several major contributions in the field of paleontology and stratigraphy. He was particularly known for his groundbreaking `` Geological Survey of the USSR '', which covered many areas of the Soviet geology. He was awarded a Presidential Commendation for his pioneering work. From 1950 until 1960 he was director of the Metallurgy Department of the State Geodetic Service. In 1959, the Geological Institute of the USSR awarded him the Royal Geographical Society's J.D. Benson Gold Medal, as it is considered to be the most prestigious academic award awarded by the U.S. Geological Survey.    From 1964 until his death in 1987, Preobrazhensky was the head of the Geological Survey of the USSR. He was one of the first representatives of geology in the United States. Between 1963 and 1972, he was the Director of the Geological Survey of the USSR. He was often seen lecturing in engineering and technology courses in the United States, and on various other occasions in Europe.He was also an important conservationist. The life-size figurine of Preobrazhensky was dedicated to the summer Labor Day commemorations. It was placed in the Plouform Museum of the Leningrad State University.                  <end_bio>")

test_data = pd.read_csv('drive/MyDrive/DL/mix_test.csv')

test_data["result"] = test_data["bio"].apply(lambda x: classifier(x)[0]['label'])

# import datasets
# from transformers import pipeline
# from transformers.pipelines.pt_utils import KeyDataset
# from tqdm.auto import tqdm

# pipe = pipeline("automatic-speech-recognition", model="facebook/wav2vec2-base-960h", device=0)
# dataset = datasets.load_dataset("superb", name="asr", split="test")

# # KeyDataset (only *pt*) will simply return the item in the dict returned by the dataset item
# # as we're not interested in the *target* part of the dataset. For sentence pair use KeyPairDataset
# for out in tqdm(pipe(KeyDataset(dataset, "file"))):
#     print(out)

def get_label(x):
  if x=="REAL":
    return 1
  else:
    return 0

test_data["pred_label"] = test_data["result"].apply(lambda x: get_label(x))

# test_data.to_csv("drive/MyDrive/DL_HW1/roberta_results.csv")

test_data[test_data["label"] == test_data["pred_label"]]

test_data["result"].value_counts()

correctly_predicted = test_data[test_data["label"] == test_data["pred_label"]]

accuracy = len(correctly_predicted)/len(test_data)
print("Transformer accuracy:", accuracy)

blind_data = pd.read_csv('drive/MyDrive/DL/blind_test_txt.csv')

blind_data["result"] = blind_data["bio"].apply(lambda x: classifier(x)[0]['label'])

blind_data

blind_data.to_csv("blind_data_results.csv")

classifier.save_pretrained('drive/MyDrive/Model_Transformer')